<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Research Tools for Social Scientists</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Research Tools for Social Scientists">
  <meta name="generator" content="bookdown <!--bookdown:version--> and GitBook 2.6.7">

  <meta property="og:title" content="Research Tools for Social Scientists" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="Thdegraaff/Research_tools_for_social_scientists" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Research Tools for Social Scientists" />
  
  
  

<meta name="author" content="Thomas de Graaff">

<meta name="date" content="2016-10-19">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<!--bookdown:link_prev-->
<!--bookdown:link_next-->

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>


<!--bookdown:title:start-->
<div id="header">
<h1 class="title">Research Tools for Social Scientists</h1>
<h4 class="author"><em>Thomas de Graaff</em></h4>
<h4 class="date"><em>October 19, 2016</em></h4>
</div>
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul>
<li><a href="#preface"><span class="toc-section-number">1</span> Preface</a></li>
<li><a href="#introduction"><span class="toc-section-number">2</span> Introduction</a><ul>
<li><a href="#why-do-we-need-all-this"><span class="toc-section-number">2.1</span> Why do we need all this?</a></li>
<li><a href="#why-use-r-and-not-other-applications"><span class="toc-section-number">2.2</span> Why use <code>R</code> and not other applications?</a></li>
<li><a href="#regression-analysis-not-again"><span class="toc-section-number">2.3</span> Regression analysis: not again!</a></li>
</ul></li>
<li><a href="#basic-r-usage"><span class="toc-section-number">3</span> Basic <code>R</code> Usage</a><ul>
<li><a href="#where-to-get-it"><span class="toc-section-number">3.1</span> Where to get it</a></li>
<li><a href="#for-absolute-beginners"><span class="toc-section-number">3.2</span> For absolute beginners</a></li>
<li><a href="#how-to-use-it"><span class="toc-section-number">3.3</span> How to use it</a><ul>
<li><a href="#subsec:scripts"><span class="toc-section-number">3.3.1</span> Scripts</a></li>
<li><a href="#help"><span class="toc-section-number">3.3.2</span> Help!</a></li>
<li><a href="#subsec:packages"><span class="toc-section-number">3.3.3</span> Packages</a></li>
<li><a href="#using-comments"><span class="toc-section-number">3.3.4</span> Using comments</a></li>
</ul></li>
<li><a href="#reading-and-writing-data"><span class="toc-section-number">3.4</span> Reading and writing data</a></li>
<li><a href="#ehmmm-dataframes"><span class="toc-section-number">3.5</span> Ehmmm, dataframes</a></li>
<li><a href="#regression-modeling"><span class="toc-section-number">3.6</span> Regression modeling</a></li>
<li><a href="#making-plots"><span class="toc-section-number">3.7</span> Making plots</a></li>
<li><a href="#recap"><span class="toc-section-number">3.8</span> Recap</a></li>
</ul></li>
<li><a href="#digression-linear-regression-and-how-to-apply-it"><span class="toc-section-number">4</span> Digression: Linear Regression and how to apply it</a><ul>
<li><a href="#sec:theory"><span class="toc-section-number">4.1</span> Theoretical background</a><ul>
<li><a href="#the-model"><span class="toc-section-number">4.1.1</span> The model</a></li>
<li><a href="#the-least-squares-assumptions"><span class="toc-section-number">4.1.2</span> The least squares assumptions</a></li>
<li><a href="#possible-violations-and-how-to-spot-them"><span class="toc-section-number">4.1.3</span> Possible violations and how to spot them</a></li>
<li><a href="#normality-heteroskedasticity-and-multicollinearity"><span class="toc-section-number">4.1.4</span> Normality, heteroskedasticity and multicollinearity</a></li>
</ul></li>
<li><a href="#sec:applications"><span class="toc-section-number">4.2</span> Applications of linear regression</a><ul>
<li><a href="#descriptives"><span class="toc-section-number">4.2.1</span> Descriptives</a></li>
<li><a href="#baseline-model"><span class="toc-section-number">4.2.2</span> Baseline model</a></li>
<li><a href="#specificion-issues"><span class="toc-section-number">4.2.3</span> Specificion issues</a></li>
<li><a href="#reporting"><span class="toc-section-number">4.2.4</span> Reporting</a></li>
<li><a href="#internal-validation"><span class="toc-section-number">4.2.5</span> Internal validation</a></li>
</ul></li>
</ul></li>
<li><a href="#network-analysis-with-r"><span class="toc-section-number">5</span> Network analysis with <code>R</code></a><ul>
<li><a href="#introduction-1"><span class="toc-section-number">5.1</span> Introduction</a></li>
<li><a href="#creating-networks"><span class="toc-section-number">5.2</span> Creating networks</a></li>
<li><a href="#reading-networks"><span class="toc-section-number">5.3</span> Reading networks</a></li>
<li><a href="#network-characteristics"><span class="toc-section-number">5.4</span> Network characteristics</a></li>
</ul></li>
<li><a href="#in-conclusion"><span class="toc-section-number">6</span> In conclusion</a></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Research Tools for Social Scientists</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="preface" class="section level1">
<h1><span class="header-section-number">1</span> Preface</h1>
<p>I started this online book as background material for the course Network Analysis and from the need to teach social science students (including Business Administration and econmonics students) the very basics of <code>R</code> and the intuition behing applying linear regression. I intend to work on this book on the fly meaning that during courses I try to see what the needs of students really are. Moreover, during the year I intend to add additional chapters, specifically about the use of stated preference modeling–and its corresponding logit estimation–and working with geographical data. Obviously, all in <code>R</code>. At the moment this book really has not yet passed its infant stage. Therefore, all input in the form of comments, critique and remarks are <em>high</em> appreciated.</p>
<!--chapter:end:index.rmd-->
</div>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">2</span> Introduction</h1>
<div id="why-do-we-need-all-this" class="section level2">
<h2><span class="header-section-number">2.1</span> Why do we need all this?</h2>
<p>A natural question that arises, or at least should arise, is why bother? Why learn students in the social sciences new tools to do research. ‘Old’ tools<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> such as <code>Word</code>, <code>Excel</code> and <code>Stata</code>do just as fine right? I would say yes, but up to a certain extent. If you are only interested in straightforward regression and anova techniques and collect your sample by survey research, then <code>Stata</code> and <code>Excel</code>(or even <code>SPSS</code>, the horror…) would definitely suffice. But if you would like to do more fancy and cool stuff, including creating beautiful diagrams, nice maps, simulation, network analysis, and even whole books in <code>html</code> then you need more elaborate tools.</p>
<p>And even though most of the best tools out there<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> are open source (so they are <strong>free</strong>, as in <strong>free beer</strong>) they will cost you something dearly: namely, your time. The learning curve of these tools are usually quite steep (which also means they will pay-off quickly). So, choose your battles carefully. The best tools, I would argue, have the following set of characteristics:</p>
<ul>
<li>They are open source. So no lock-in effects anymore with datasets (<code>Stata</code>) or versions (<code>Word</code>).</li>
<li>They are scriptable. This means they can “communicate” with other programs. Usually this means that these tools revolve around <code>.txt</code> files.</li>
<li>There is a large community that uses these tools. This is very handy for supplementary material and solving questions.</li>
<li>They are multi-purpose, which means you can use them for various purposes. This is actually only a requirement of the data management/statistics you use.</li>
</ul>
<p>One of the tools that meets all these requirements, and more, is <code>R</code> and the next section lays out why even social scientists should learn <code>R</code>.</p>
</div>
<div id="why-use-r-and-not-other-applications" class="section level2">
<h2><span class="header-section-number">2.2</span> Why use <code>R</code> and not other applications?</h2>
<p>Ask any data scientist at the moment for the software tools most used and they will most likely answer <code>R</code> or <code>Python</code>. Of course, that should not be a valid answer (many people use <code>Word</code> as well and nobody would argue that <code>Word</code> is brilliant), but it indicates the popularity (and the community) that uses <code>R</code>.</p>
<p>Where 10 years ago most social scientists still used <code>SPSS</code> (and the economists <code>Stata</code>), that has now changed completely (well the economists still use <code>Stata</code> but the rest of the world moved on). And for good reasons, namely:</p>
<ol style="list-style-type: decimal">
<li>It is open source and thus free;</li>
<li><code>R</code> is flexible and thus multi-purpose;</li>
<li>there is now a <strong>very</strong> large userbase; everything you can dream of (well sort of), somebody else most likely already programmed;<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></li>
<li>it generates beautiful pictures, diagram, maps, and histograms (even pie diagrams);</li>
<li>relative to <code>Stata</code> or <code>Excel</code> it is fast, which is great for larger (spatial) databases.</li>
</ol>
<p>In general, you can use <code>R</code> for statistical analysis, simulation analysis, data management, visual display of data, creating documents (and presentations), and even GIS applications. In that respect it is far more flexible than <code>Stata</code>. Last but perhaps not least, <code>R</code> is more and more used outside academia as well. Twitter, Facebook and Google use <code>R</code>, but companies as the NY times as well for interactive website diagrams.</p>
</div>
<div id="regression-analysis-not-again" class="section level2">
<h2><span class="header-section-number">2.3</span> Regression analysis: not again!</h2>
<p>I will also spend some time on the use of regression analysis and try to explain in my own words how to use it. In general, my experience is that many students have little or no experience in regression analysis. Moreover, and perhaps even worse, they have little or no intuition for regression analysis. This sort of sucks, the more because regression is the most often statistical technique used in the social sciences (heck, in all sciences).</p>
<p>In my perception, students are taught the principles of statistics (typically this involves lots of things as ANOVA), where in the last course, one or two hours is spent on regression analysis. This is fine, as long as it comes back in a course as <em>applied</em> statistics or econometrics (how and when to do this stuff?) or in other applied courses. But usually this is not the case. Most courses don’t care about regression analysis and the first moment you have to use it again is when writing your thesis and at that time it is a bit too late to teach the applied stuff again.</p>
<p>So, yeah, therefore a bit of regression analysis from my perspective. But again, you only learn this by doing and under the guidance of various teachers (and in various cirumstances).</p>
<!--chapter:end:01-introduction.Rmd-->
</div>
</div>
<div id="basic-r-usage" class="section level1">
<h1><span class="header-section-number">3</span> Basic <code>R</code> Usage</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;swirl&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;rio&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;ggplot2&quot;</span>)</code></pre></div>
<p>The <code>R</code> programming language and software environment for statistical computing is an implementation of the proprietary <code>S</code> programming language by Ross Ithaka and Robert Gentleman in 1992. It quickly gained in popularity (see, e.g, this Nature article from 2014 <a href="http://www.nature.com/news/programming-tools-adventures-with-r-1.16609">Programming tools: Adventures with R</a>) and now has more than 8,000 user contributed packages (see as well the blog piece <a href="https://www.r-bloggers.com/on-the-growth-of-cran-packages/">On the growth of CRAN packages</a>).</p>
<div id="where-to-get-it" class="section level2">
<h2><span class="header-section-number">3.1</span> Where to get it</h2>
<p>First, you need to install <code>R</code> itself. You can do this by downloading this from <a href="http://cran.xl-mirror.nl/">CRAN</a> (we choose here the server from the Netherlands). Choose your appropriate operating system, choose the <code>base</code> system, download <code>R</code> and install it. That’s it!</p>
<p>The base distribution of <code>R</code> comes with a built-in editor, where you can write your script (more about scripts in subsection @ref(subsec:scripts)). This editor is however <em>very</em> basic. Therefore, it is very much advised that you download and install the Open Source editor <a href="https://www.rstudio.com/products/rstudio/download/"><code>RStudio</code></a> as well. Again, choose your operating system and just install the latest version. The very short video (1.5 minutes) on RStudio’s <a href="https://www.rstudio.com/products/rstudio/">website</a> gives an overview of the <em>basic</em> features (it can do quite some more stuff).</p>
</div>
<div id="for-absolute-beginners" class="section level2">
<h2><span class="header-section-number">3.2</span> For absolute beginners</h2>
<p>At the moment there are <em>many</em> tutorials, blogs, youtube clips, and background materials about using <code>R</code> on the internet. I therefore do not intend to write a complete handbook, but focus instead on what I need for my courses. Moreover, I do not intend to teach the very basic stuff. There is very good tutorial package out there called Swirl (see as well the website: <a href="http://swirlstats.com/students.html" class="uri">http://swirlstats.com/students.html</a>). I very much recommend using this package for absolute beginners. The way to do this is rather simple. First install the package by typing:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;swirl&quot;</span>)</code></pre></div>
<p>then start Swirl by first loading the package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;swirl&quot;</span>)</code></pre></div>
<p>And then call the function by typing:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">swirl</span>()</code></pre></div>
<p>In the first menu choose <code>R Programming</code>. Now, there are 15 lessons. I find the first four the most useful (Basic Building Block, Workspace and Files, Sequences of Numbers, Vectors), but others are very useful as well to go through. The command <code>main()</code> by the way brings you always back to the main menu, and do not go for the credits on coursera (that is now a paid online course).</p>
</div>
<div id="how-to-use-it" class="section level2">
<h2><span class="header-section-number">3.3</span> How to use it</h2>
<p><code>R</code> is truly a programming language in the sense that there is no graphical user interface (GUI) involved. You need to type your own commands. And for beginners this sort of sucks. It seems slower, you have no idea which commands to type in, and you frequently make many mistakes. However, when you start to use it more, speed of getting things done goes up (sometimes exponentially), you have a better grasp on the basic commands, and the number of mistakes go down. In contrast with programs such as <code>Excel</code> or <code>SPSS</code>, there are two big differences: (<em>i</em>) you use scripts and (<em>ii</em>) you make frequently use of packages which are essentially written by other <code>R</code> users.</p>
<div id="subsec:scripts" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Scripts</h3>
<p>The use of scripts or program files is somewhat alien to most. Although <code>Stata</code> also makes use of so-called <code>do</code> files. You start a new script by clicking on File &gt; New Script (<code>R</code> editor) or File &gt; New File &gt; New Script (<code>RStudio</code>). You now have a new <em>empty</em> file (which you have to save from time to time). If you fill in this file with commands, you are actually programming. The <strong>huge</strong> benefit of this procedure is that you record what you have done and that you can easily change something.</p>
<p>As an example, assume that somebody gives you a dataset with 2 variables and ask you to analyse this dataset. With <code>SPSS</code> you read this dataset in and then click on various butttons so you get some output. Now, assume further that this person actually has forgotten a variable (this happens more often than you think) and gives you a new dataset with 3 variables. Then you have to do all the clicking again (and hopefully you remembered on which buttons you actually clicked).</p>
<p>When you have a script file you only have to change the code in 1 or 2 places and run it all again. No sweat! So, writing up all the commmands and save it for later, might cost you some time in the <strong>beginning</strong>, but there are <strong>huge</strong> time savers later on! To run a script you simply need to press the button Edit &gt; Run all (<code>R</code> editor) or Code &gt; Run Region &gt; Run All (<code>RStudio</code>). Nobody does that however, because there are numerous Keyboard Shortcuts (I advise you to learn them, because they make you considerably faster. Actually, most Keyboard Shortcuts work in a wide variety of editors–even in <code>Word</code>.)</p>
</div>
<div id="help" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Help!</h3>
<p>Sometimes you have found a command you would think you could use, but you do not know how, then you need to use <code>?</code> operator in front of the command. For instance, you know that the command <code>c()</code> could be useful, but how? Then type:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?<span class="kw">c</span>()</code></pre></div>
<p>And the appropiate documentation will pop up.</p>
</div>
<div id="subsec:packages" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Packages</h3>
<p><code>R</code> (as many other software applications nowadays) depends heavily on packages written by other parties, usually users of <code>R</code>. There are now many packages out there. You can find the ‘official’ ones on <a href="https://cran.r-project.org/web/packages/available_packages_by_name.html">the CRAN website</a>, but there are many more. Packages have to be installed (both <code>R</code> editor and <code>RStudio</code> have a separate package manager) and afterwards loaded. Say, for instance we want to use the awesome <code>ggplot2</code> package (a package to make plots look nice, actually to make more elaborate plots but anyway), then to install and load the package we give the commands:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;ggplot2&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;ggplot2&quot;</span>)</code></pre></div>
<p>Now, we can use the commands from this package as if they were built-in.</p>
<p>Gradually, we come across some useful packages. Those we will use in a chapter will always be listed at the start of the chapter.</p>
</div>
<div id="using-comments" class="section level3">
<h3><span class="header-section-number">3.3.4</span> Using comments</h3>
<p>A final word in this section about the use of comments. <strong>Do it!</strong>. Really, it will make your future life much easier if you have documented what you have done. You can insert comments by using the <code>#</code> operator (everything after the hashtag is a comment), so, e.g.,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2+2</span> <span class="co"># always wanted to know about the outcome, but were afraid to ask</span></code></pre></div>
</div>
</div>
<div id="reading-and-writing-data" class="section level2">
<h2><span class="header-section-number">3.4</span> Reading and writing data</h2>
<p>To properly do statistics one needs data (duh!). Luckily, there are numerous ways to get data in <code>R</code>.</p>
<p>When you just have a <code>csv</code> text file (comma separated file), it is easy, you just type:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="dt">file=</span><span class="st">&quot;my_data.csv&quot;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>and you read in the <code>data.csv</code> in a data frame variable called <code>df</code>. Note that the original header variables are preserved. If you would like to store your data you can do the reverse, namely:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">write.csv</span>(df, <span class="dt">file =</span> <span class="st">&quot;my_data.csv&quot;</span>)</code></pre></div>
<p>Now sometimes you do not have nicely formatted <code>.csv</code> or <code>.txt</code>files, but nasty <code>.dta</code> files from Stata or <code>.xlsx</code> files from <code>Excel</code>. Here the package Rio comes very handed, being the swiss-army knife of data converters in <code>R</code>. Assume you have the <code>mtcars</code> dataset in various formats, then you can do</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;rio&quot;</span>)

x &lt;-<span class="st"> </span><span class="kw">import</span>(<span class="st">&quot;mtcars.sav&quot;</span>)  <span class="co"># SPSS data file</span>
y &lt;-<span class="st"> </span><span class="kw">import</span>(<span class="st">&quot;mtcars.xlsx&quot;</span>) <span class="co"># Excel data file</span>
z &lt;-<span class="st"> </span><span class="kw">import</span>(<span class="st">&quot;mtcars.dta&quot;</span>)  <span class="co"># Stata data file</span></code></pre></div>
<p>and all dataframes <code>x</code>, <code>y</code> <code>z</code> should be identical.</p>
</div>
<div id="ehmmm-dataframes" class="section level2">
<h2><span class="header-section-number">3.5</span> Ehmmm, dataframes</h2>
<p>I already talked a bit about dataframes, but have not yet explained what they are. Simply, it is your data. Lets construct a simple dataframe:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Names  &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Thomas&quot;</span>, <span class="st">&quot;Erik&quot;</span>, <span class="st">&quot;Mark&quot;</span>, <span class="st">&quot;Eveline&quot;</span>)
Grades &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">8</span>, <span class="fl">6.5</span>, <span class="dv">7</span>)
Female &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="ot">FALSE</span>,<span class="ot">FALSE</span>,<span class="ot">FALSE</span>,<span class="ot">TRUE</span>)

df_grades &lt;-<span class="st"> </span><span class="kw">data.frame</span>(Names, Grades, Female) </code></pre></div>
<p>First,note a couple of things. A dataframe can consists of various data_types, in this case strings (the names), numbers (the grades) and so-called Booleans (someone is female or not). Secondly, we have names the variables. So, we now have a dataframe called df_grades. Great, now what? Well, we can do a couple of things. By using the command <code>head()</code> we can show the first 6 rows of this dataframe.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(df_grades)</code></pre></div>
<pre><code>##     Names Grades Female
## 1  Thomas    5.0  FALSE
## 2    Erik    8.0  FALSE
## 3    Mark    6.5  FALSE
## 4 Eveline    7.0   TRUE</code></pre>
<p>Because we only have four observations this actually gives our whole dataframe (you can also just type <code>df_grades</code> to get this). Using square brackets <code>[]</code> allows you get specific information from this dataset, where the first index denotes the row and the second index denotes the column. Look at the following examples:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df_grades[<span class="dv">1</span>,<span class="dv">2</span>]</code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df_grades[<span class="dv">1</span>,]</code></pre></div>
<pre><code>##    Names Grades Female
## 1 Thomas      5  FALSE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df_grades[<span class="dv">3</span>]</code></pre></div>
<pre><code>##   Female
## 1  FALSE
## 2  FALSE
## 3  FALSE
## 4   TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df_grades[<span class="st">&quot;Names&quot;</span>]</code></pre></div>
<pre><code>##     Names
## 1  Thomas
## 2    Erik
## 3    Mark
## 4 Eveline</code></pre>
<p>Most of the statistical stuff we will do invokes the use of dataframe and specific variables from that dataframe.</p>
</div>
<div id="regression-modeling" class="section level2">
<h2><span class="header-section-number">3.6</span> Regression modeling</h2>
<p>Before we start laying-out how to do regression modeling in <code>R</code>, we first need data. And for this purpose we will simulate our data by the following commands:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">100</span>, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">1</span>) <span class="co"># create 100 uniformly distributed numbers in interval (0,1)</span>
y &lt;-<span class="st"> </span><span class="dv">2</span> +<span class="st"> </span><span class="dv">6</span>*x +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>) <span class="co"># rnorm stands for the normal distribution</span>
df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(y,x) <span class="co"># Strictly not necessary but for the sake of the exposition</span></code></pre></div>
<p>So in fact we have now created the following model:</p>
<p><span class="math display">\[
y_i = 2 + 6 x_i + \epsilon_i,
\]</span> where <span class="math inline">\(\epsilon_i\)</span> is standard normally distributed (as I will explain later in Section @ref(sec:theory) this is for convenience but <strong>not</strong> absolutely needed to do linear regression).</p>
<p>checking this with</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(df)</code></pre></div>
<pre><code>##          y         x
## 1 3.835505 0.2435226
## 2 3.750405 0.4186126
## 3 7.330236 0.6993083
## 4 5.152201 0.5243399
## 5 5.296860 0.3917182
## 6 7.165345 0.8207766</code></pre>
<p>indeed shows the first 6 combination of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. If we now perform a linear regression, then we expect that the estimated intercept should be very close to 2 and the estimated slope parameter should be very close to 6. In <code>R</code> we have the command <code>lm()</code> (from linear model) to do this as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">linear_model &lt;-<span class="st"> </span><span class="kw">lm</span>(y~x, <span class="dt">data =</span> df)</code></pre></div>
<p>We now have performed a regression of <span class="math inline">\(y\)</span> onto <span class="math inline">\(x\)</span>, using the data <code>df</code> and save the result in a variable called linear_model. First note the first part of the <code>lm(,)</code> expression. <code>y~x</code> means that <code>y</code> is the left-hand side variable and <code>x</code> the righ-hand side variable (if we have more variables, the formula becomes something as<code>y~x+u+v+w+z</code>). The second part of the <code>lm(,)</code> expression denotes the specific dataframe to be used. Namely, in <code>R</code> you can have multiple dataframes so you have to specify which one is to be used.</p>
<p>Right, but now what? Well, we have now a variable called linear_model, just typing in <code>linear_model</code> only gets you the real basic results:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">linear_model</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = df)
## 
## Coefficients:
## (Intercept)            x  
##       1.984        6.210</code></pre>
<p>But, you want more, right? Standard errors, t-statistics, R-squares, the whole lot. For this, you need the <code>summary()</code> command, which gives you the following outcome</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(linear_model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.4490 -0.5008  0.0622  0.6421  1.7899 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   1.9842     0.1614   12.29   &lt;2e-16 ***
## x             6.2097     0.3092   20.08   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9421 on 98 degrees of freedom
## Multiple R-squared:  0.8045, Adjusted R-squared:  0.8025 
## F-statistic: 403.2 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Interestingly, our parameters are close to 2 and 6, but not that close (which happens with a limited amount of observations, notice as well the relatively large standard errors). So, the command <code>summary()</code> gives all the needed statistical output, but what about regression diagnostics. For this you can ask for a plot of the variable linear_model</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(linear_model)</code></pre></div>
<p><img src="unnamed-chunk-19-1.png" width="672" /><img src="unnamed-chunk-19-2.png" width="672" /><img src="unnamed-chunk-19-3.png" width="672" /><img src="unnamed-chunk-19-4.png" width="672" /></p>
<p>And that is basically it, at least for the basics. There is much more to say about the <code>lm()</code> command, but that is for later.</p>
</div>
<div id="making-plots" class="section level2">
<h2><span class="header-section-number">3.7</span> Making plots</h2>
<p>Where <code>R</code> truly shines is in making plots, diagrams, histograms, etcetera. The first thing with data you want to do is to make a scatterplot. With our <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> data this can be easily done by:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(x,y)</code></pre></div>
<p><img src="unnamed-chunk-20-1.png" width="672" /></p>
<p>If you would like to create a histogram, just use <code>hist()</code> as</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(y)</code></pre></div>
<p><img src="unnamed-chunk-21-1.png" width="672" /></p>
<p>However, to go one step further you also make a plot of a dataframe. for our df dataframe this is not very insightful, but let’s add another variable <span class="math inline">\(z\)</span> uncorrelated with <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> and then plot the dataframe (the <code>$</code> indicate that <code>z</code> is a variable in dataframe <code>df</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df$z &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">100</span>, <span class="dv">0</span>,<span class="dv">1</span>)
<span class="kw">plot</span>(df)</code></pre></div>
<p><img src="unnamed-chunk-22-1.png" width="672" /></p>
<p>And luckily, this plot confirms what we expect. <span class="math inline">\(x\)</span> are correlated <span class="math inline">\(y\)</span> by construction and <span class="math inline">\(z\)</span> is not correlated with either <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. These are all the so-called baseline plots. They are great (and already highly customizable), but lately there has been a new kid on the block called ggplot2. It goes to far to explain the details of ggplot2 (gg here stands for the grammar of graphics), but suffice to say that ggplot2 works with building blocks, so that every piece of the figure that you want (or can think of) can be constructed. Just as an example, let’s redo our scatterplot but now using ggplot2 and say we want to add some density lines from our observations (just because we can). This can be done in the following way</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(x,y))+<span class="kw">geom_point</span>() +<span class="st"> </span><span class="kw">geom_density2d</span>()</code></pre></div>
<p><img src="unnamed-chunk-23-1.png" width="672" /></p>
</div>
<div id="recap" class="section level2">
<h2><span class="header-section-number">3.8</span> Recap</h2>
<p>For the absolute beginner <code>R</code> is huge and daunting. You need to learn by taking small steps and by practicing (a lot). Do not aim immediately at big and complex projects but start small and at the basics. You will then learn that you quickly make progress and at a certain time even become efficienter than when using mousing driven tools (clicking) as <code>Excel</code> or <code>SPSS</code>. In later chapters I dive in to some more detailed topics, and hopefully the material provides you with a background solid enough to understand and work with those topics using <code>R</code>.</p>
<!--chapter:end:02-usingr.Rmd-->
</div>
</div>
<div id="digression-linear-regression-and-how-to-apply-it" class="section level1">
<h1><span class="header-section-number">4</span> Digression: Linear Regression and how to apply it</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;stargazer&quot;</span>)</code></pre></div>
<p>In the social sciences (in fact, in all sciences) linear regressions (also called OLS or ordinary least squares) or one of its relatives is the most <em>used</em> empirical research tool there is. Why? It is relatively simple, computationally fast, easy to interpret and relies on a relatively weak set of assumptions. Unfortunately, the assumptions needed to be able to apply linear regression, are often not well understood: both in the social sciences and beyond. Moreover, students in the social sciences typically get little guidance in how to apply linear regression in practice and how to interpret the results. Note that this does not have anything to do with the specific software students use, but more with that fact that regression techniques in a wide number of situations (courses) are just not given (apart from statistical or research methods courses). However, given the fact that data becomes increasingly more available, knowing when to use regression techniques, how to apply them and especially how to interpret and assess them is now becoming an issue of paramount importance. Or, perhaps more compelling, you need them to write your thesis.</p>
<p>In this chapter, I will first focus in section @ref(sec:theory) on the <em>essential</em> theory behind regression analysis. I really keep it to the bare minimum. But if you understand these basics, I would argue that you understand more than 75% of the theorical background (the rest if just nitty-gritty). Section @ref(sec:applications) will focus on applications of linear regression, specification issues (how many variables) and how to interpret the results.</p>
<div id="sec:theory" class="section level2">
<h2><span class="header-section-number">4.1</span> Theoretical background</h2>
<p>This subsection first deals with the model (what are you trying to explain), then about the three critical assumptions of (ordinary) least squares, discusses subsequently typical situations when these assumptions are violated, and finishes with a discussion about less important stuff (on which, alas, quite some attention is given in bachelor courses).</p>
<p>Before we start, I would like to make one important remark. In general, statistical models can be used for (<em>i</em>) finding <strong>statistical</strong> relations, finding (<em>ii</em>) <strong>causal</strong> relations and for (<em>iii</em>) <strong>predicting</strong>. All three uses require the same assumptions, but have different focuses. In statistics, generally the focus is on finding statistical relations, such as whether the Dutch population is <em>on average</em> taller then the German population. In economics the focus is very much on finding causal relations, so the need for explanatory power is not very large. Models that do not explain much (where the <span class="math inline">\(R^2\)</span>’s are low, say <span class="math inline">\(&lt;\)</span> 0.2) are just as good as models that explain quite a lot, as long as the least squares assumptions hold. In transportation science in general (and other disciplines that deals with making large models) predictions and thus eplanatory power is key. Here it is now very important that you perfectly understand what causes what as long as out-of-sample predicting is good (say for predicting future commuting flows).</p>
<p>I usually have finding causal relations in mind when talking about least squares (already difficult enough), but note again that the same least squares assumptions should hold when you want to predict or want to find statistical relations.</p>
<div id="the-model" class="section level3">
<h3><span class="header-section-number">4.1.1</span> The model</h3>
<p>Assume we are interested in the effect of the weight of a car on the fuel efficiency of the car (measures in miles per gallon). We state the following univariate regression model: <span class="math display">\[
y_i = \alpha + \beta x_i + \epsilon_i,
\]</span> where <span class="math inline">\(y\)</span> denotes the fuel efficiency of the car, <span class="math inline">\(x\)</span> denotes the weight of the car and subscript <span class="math inline">\(i\)</span> stands for the <span class="math inline">\(i\)</span>-th observation. <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are the parameters of the model and they are <strong>unknown</strong> so have to be <strong>estimated</strong>. <span class="math inline">\(\epsilon\)</span> is a so-called error term and denotes all the variation that is not captures by our two variables (<span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>) and our weight variable <span class="math inline">\(x\)</span>.</p>
<p>The following observations are rather important:</p>
<ol style="list-style-type: decimal">
<li>What is on the left hand side of the <span class="math inline">\(=\)</span> sign is what is to be explained (in this case miles per gallon). What is on the right hand side is what we use to explain <span class="math inline">\(y\)</span>. In this case <span class="math inline">\(x\)</span>, the weight of the car.</li>
<li>The parameters <span class="math inline">\(\alpha\)</span> en <span class="math inline">\(\beta\)</span> constitute a <strong>linear</strong> relation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span></li>
<li>The parameter <span class="math inline">\(\alpha\)</span> is the constant and in the univariate setting denotes where the linear relation crosses the <span class="math inline">\(y\)</span>-axis.</li>
<li><span class="math inline">\(\beta\)</span> gives the impact of <span class="math inline">\(x\)</span> on <span class="math inline">\(y\)</span>. Because it is a linear relation, the effect is simple. One unit change of <span class="math inline">\(x\)</span> is associated with a <span class="math inline">\(\beta\)</span> change of <span class="math inline">\(y\)</span>. In general, we can say that <span class="math inline">\(\beta\)</span> is equal to the marginal effect (<span class="math inline">\(\frac{\partial y}{\partial x}\)</span>). Moreover, in a univariate setting <span class="math inline">\(\beta\)</span> denotes the slope of the relation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</li>
<li>The regression error term <span class="math inline">\(\epsilon\)</span> gives all variation that is not captured by our model, so <span class="math inline">\(y_i -(\alpha + \beta x_i) = \epsilon_i\)</span>. In this case, weight of the car most likely does not capture all variation in miles per gallon, so quite some variation is left in <span class="math inline">\(\epsilon\)</span>. Something else is captured as well by <span class="math inline">\(\epsilon\)</span> and that is the measurement error of <span class="math inline">\(y\)</span>. So, if we have not measured miles per gallon precisely enough then that variation is captured as well by <span class="math inline">\(\epsilon\)</span>.</li>
</ol>
<p>Now, let’s assume that we want to incorporate another variable (say the number of cylinders <span class="math inline">\(c\)</span>), because we think that that variable is very important in explaining miles per gallon. Then we get the following <em>multivariate</em> regression model: <span class="math display">\[
y_i = \alpha + \beta_1 x_i + \beta_2 c_i + \epsilon_i,
\]</span> where we now have two variables on the right hand side (<span class="math inline">\(x_i\)</span> and <span class="math inline">\(c_i\)</span>) and three parameters (<span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span>). In effect nothing changes with the intuition behind the model. Except for the interpretation of the parameter <span class="math inline">\(\beta_1\)</span> (and thus also <span class="math inline">\(\beta_2\)</span>). Parameter <span class="math inline">\(\beta_1\)</span> now measures the impact of <span class="math inline">\(x\)</span> on <span class="math inline">\(y\)</span> <em>holding <span class="math inline">\(c\)</span> constant</em>. So, multivariate regression models is nothing more (and less) than controlling for other factors. And we see later why that is very important.</p>
</div>
<div id="the-least-squares-assumptions" class="section level3">
<h3><span class="header-section-number">4.1.2</span> The least squares assumptions</h3>
<p>We are interested in the effect of the weight of the car on fuel efficiency and,therefore, our <strong>estimate</strong> of <span class="math inline">\(\beta_1\)</span> should be very close to the <strong>true</strong> <span class="math inline">\(\beta_1\)</span>, especially when we have a large number of observations. Regression is great and utterly brilliant in finding this estimate, as long as the following three least squares assumptions hold:</p>
<ol style="list-style-type: decimal">
<li>There are no large outliers</li>
<li>All left hand side (in this case <span class="math inline">\(y\)</span>) and right side variables (in this case <span class="math inline">\(x\)</span> and <span class="math inline">\(c\)</span>) are <em>i.i.d.</em></li>
<li>For the error term the following must hold: <span class="math inline">\(E[\epsilon|X=x] = 0\)</span>.</li>
</ol>
<p>The first one is easy to understand. OLS is very sensitive to large outliers in the dataset. It is therefore always good to look for outliers and think whether they are <em>real</em> observations or perhaps typo’s (in Excel or something). Do not throw outliers immediately away but check whether they are correct.</p>
<p>The second is relatively easy to understand as well (but not that much in practice). <em>i.i.d.</em> in this case stands for independently and identically distributed. This basically means that the observations in your dataset are independent from each other: in other words, the observations should have been correctly <em>sampled</em>.</p>
<p>The third looks the most horrible, and, to be quite honest, is so–both in theory as in reality. This is also the assumption that is least well understood. And especially in assessing whether regression output is correct (is your estimate <em>really</em> close to <span class="math inline">\(\beta_1\)</span>) this assumption is crucial.</p>
</div>
<div id="possible-violations-and-how-to-spot-them" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Possible violations and how to spot them</h3>
<p>A violation of the first assumption is usually easy to spot. There is a very strange outlier. But this also marks the importance of analysing <em>descriptive statistics</em>, including means, maximums and minimums, scatterplots and histograms.</p>
<p>Whether your data is not <em>i.i.d.</em> can come because of a couple of reasons. The most straightforward is getting your data via snowballing (asking your friends and families using facebook to fill in a questionnaire and to ask their friends and families to do so as well). Usually, this means that you have a very specific sample and that the estimate you get is not close to the true value for the whole population. Observations might also be dependent upon each other, because of unobserved factors. In our case, it might be that a type of cars (American) are less fuel efficient than other cars (European).</p>
<p>Another typical violation of the <em>i.i.d.</em> assumption is in time-series, where what happened in the previous period might have a large effect on the current period.</p>
<p>In general, however, violations of the <em>i.i.d.</em> property are not that devestating for your model as long as you are only interested in finding the true <span class="math inline">\(\beta_1\)</span>: namely, it usually only affects the precision of your estimate (the standard error) and not the estimate itself. When this assumption is violated, we therefore say that the estimate is <strong>inefficient</strong>. When you want to predict however, this assumption is crucial, as you would like your estimate to be <em>as precise</em> as possible.</p>
<p>When the third assumption is violated, we say that our estimate is <strong>biased</strong>, in other words <strong>wrong</strong>: our parameter estimate does not come close to the true parameter. And this happens more often than not. So, what does <span class="math inline">\(E[\epsilon|X=x] = 0\)</span> actually mean. Loosely speaking, the parameters on the right hand side (in our case <span class="math inline">\(x\)</span> and <span class="math inline">\(c\)</span>) and the error term (<span class="math inline">\(\epsilon\)</span>) are not allowed to be correlated. There are several ways that this might happen, from which the following are in our case the most relevant:</p>
<ol style="list-style-type: decimal">
<li><p>Reverse causality: <span class="math inline">\(x\)</span> impacts <span class="math inline">\(y\)</span>, but <span class="math inline">\(y\)</span> might impact <span class="math inline">\(x\)</span> as well. This is the classical chicken and egg problem. Do firm perform better because of good management, or do good managers go to the better performing firms?</p></li>
<li><p>Unobserved heterogeneity bias: there are factors that are not in the model but influence both <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. For example, if american cars have both an influence on fuel efficiency and weight of the cars then the estimate that we find is not close to the true value of <span class="math inline">\(\beta_1\)</span>.</p></li>
<li><p>Misspecification: we assume that our model is linear, but it actually is not. Then, again, our estimate that we find is not close to the true value of <span class="math inline">\(\beta_1\)</span>.</p></li>
</ol>
<p>There are other sources of violations, but in this case, these are the most important ones. Reverse causality is usually hard to correct for, but unobserved heterogeneity bias is luckily easier. Namely, we add <em>relevant</em> control variables (as we did with <span class="math inline">\(c\)</span>). In this case we can <em>minimize</em> possible unobserved heterogeity bias. Misspefications are in general as well relative easy to correct for. From our descriptive statistics and scatterplot we usually can infer the relation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> and control for possible nonlinearities by using (natural) logarithms and squared terms.</p>
<p>As a sidenote, natural logarithms are the ones most used for various reasons not discussed here. If we take the logarithm of both sides then for our univariate regression we get: <span class="math display">\[
\ln(y_i) = \alpha + \beta \ln(x_i) + \epsilon_i,
\]</span> and all the aforementioned rules and assumptions still apply. But there is something peculiar to this regression. Namely, if we are interested in the marginal effect (<span class="math inline">\(\frac{\partial y}{\partial x}\)</span>), we get the following: <span class="math display">\[
\frac{\partial y}{\partial x} = \frac{\partial e^{\ln(y_t)}}{\partial x} = \frac{\partial e^{(\alpha + \beta \ln(x_i) + \epsilon_i)}}{\partial x} = \frac{\beta}{x}e^{(\alpha + \beta \ln(x_i) + \epsilon_i)} = \frac{\beta}{x}y, 
\]</span> In other words: <span class="math display">\[
\beta = \frac{\partial y}{\partial x} \frac{x}{y}
\]</span> which is simply the <strong>elasticity</strong> between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. So, if there are logarithms on both the left and right hand side then the parameters (the <span class="math inline">\(\beta\)</span>’s) denotes elasticities.</p>
</div>
<div id="normality-heteroskedasticity-and-multicollinearity" class="section level3">
<h3><span class="header-section-number">4.1.4</span> Normality, heteroskedasticity and multicollinearity</h3>
<p>Until now, we have not discussed the concepts normality, heteroskedasticity and multicollinearity. That is simply because they are not that relevant (as long as we have enough observations, typically above 40). The validity of OLS hinges just upon the three assumptions mentioned above (and they are already difficult enough). In fact, if the three assumptions are satisfied, then, as an <strong>outcome</strong>, the parameters (<span class="math inline">\(\beta\)</span>) are normally distributed. It goes to far to explain why (the theorems required for this are deeply fundamental to statistics), but in any case, normality is <strong>not</strong> a core OLS assumption. It would be nice if both <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> are normally distributed because then the standard errors are minimized, but again, whether the estimate of <span class="math inline">\(\beta\)</span> you find is correct or not (biased or unbiased) does not depend on normality <strong>assumptions</strong>.</p>
<p>Heteroskedasticy (in other words your standard errors are not constant) as well leads to quite some confusion. In general heteroskedasticity only leads to inefficient estimates (so only affects the standard errors). Nothing more, nothing less. And there are corrections for that (robust standard errors in <code>Stata</code> and similar procedures in <code>R</code>), so that nobody needs to care anymore about heteroskedasticity.</p>
<p>Finally, there is multicollinearity. And this come in two flavours: perfect and imperfect multicollinearity. Perfect multicollinearity occurs, e.g., when your model contains two identical variables. Then, OLS can not decide which one to use and usually one of the variables is dropped, or your computer program gives an error (<em>computer says no</em>).</p>
<p>Imperfect multicollinearity occurs when two variables are highly (but not perfectly) correlated. This occurs less often than one may think. Variables that are highly correlated (say <span class="math inline">\(age\)</span> and <span class="math inline">\(age^2\)</span>) can be perfectly incorporated in a model. Only when the correlation becomes very high (say above 95% or even higher) then something strange happens: the standard errors get very large. Why? That is because of the definition mentioned above. Parameter <span class="math inline">\(\beta_1\)</span> measures the impact of <span class="math inline">\(x\)</span> on <span class="math inline">\(y\)</span> <em>holding <span class="math inline">\(c\)</span> constant</em>. But if <span class="math inline">\(x\)</span> and <span class="math inline">\(c\)</span> are very highly correlated and you control for <span class="math inline">\(c\)</span>, then not much variation is left over for <span class="math inline">\(x\)</span>. So, <span class="math inline">\(c\)</span> actually removes the variation <em>within</em> the variable <span class="math inline">\(x\)</span>. This always happens, and there is a trade-off between adding more variables and leaving enough variation (note that there is always correlation between variables), but usually it all goes fine. Good judgement and sound thinking typically helps more than strange statistics (say VIF?).</p>
</div>
</div>
<div id="sec:applications" class="section level2">
<h2><span class="header-section-number">4.2</span> Applications of linear regression</h2>
<p>This section gives an application of regression analysis. Assume we are still interested in the effect of the weight of a car on the fuel efficiency of the car (measures in miles per gallon). We have found a dataset (internal in <code>R</code>), so the first thing we have to do is look at the descriptives of the dataset.</p>
<div id="descriptives" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Descriptives</h3>
<p>The build-in dataset <code>mtcars</code> has, besides several other variables, information on weight of a car in (1000 lbs or in about 450 kilos) and miles per gallon. With the following command <code>head()</code> we can look at the first 6 observations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(mtcars)</code></pre></div>
<pre><code>##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1</code></pre>
<p>Again, we are interested in the relation weight of a car (the variable <code>wt</code>) and miles per gallon (the variable <code>mpg</code>). Note, that in his case <code>mpg</code> is the first column and <code>wt</code> is the sixth column. (The column with car names above is not a real variable, but are the row names). Recall that the command <code>c()</code> combines stuff, so we can look at the summary statistics of the variables we are only interested in by:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(mtcars[,<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">6</span>)])</code></pre></div>
<pre><code>##       mpg              wt       
##  Min.   :10.40   Min.   :1.513  
##  1st Qu.:15.43   1st Qu.:2.581  
##  Median :19.20   Median :3.325  
##  Mean   :20.09   Mean   :3.217  
##  3rd Qu.:22.80   3rd Qu.:3.610  
##  Max.   :33.90   Max.   :5.424</code></pre>
<p>There does not seem to be anything out of the ordinary here, but to be sure, we construct a scatterplot between weight of the car and miles per gallon.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(mpg~wt, mtcars)</code></pre></div>
<div class="figure">
<img src="unnamed-chunk-27-1.png" alt="A scatterplog between miles per gallon and car weight." width="672" />
<p class="caption">
(#fig:unnamed-chunk-27)A scatterplog between miles per gallon and car weight.
</p>
</div>
<p>So, there do not seem to be many outliers here. Moreover, as we would expect, there seems to be a downward sloping relation between weight of the car and miles per gallon (hopefully you agree, that this makes sense). To <strong>quantify</strong> this relation, the next subsection will perform a least squares estimation.</p>
</div>
<div id="baseline-model" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Baseline model</h3>
<p>So, if we are only interested in the relation between weight of a car (the variable <code>wt</code>) and miles per gallon, we can easily perform the following regression (recall again that the command <code>lm()</code> performs a least squares estimation and that <code>&lt;-</code> denotes an assignment to a variable:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">baselinemodel &lt;-<span class="st"> </span><span class="kw">lm</span>(mpg~wt, mtcars)
<span class="kw">summary</span>(baselinemodel)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.5432 -2.3647 -0.1252  1.4096  6.8727 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***
## wt           -5.3445     0.5591  -9.559 1.29e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.046 on 30 degrees of freedom
## Multiple R-squared:  0.7528, Adjusted R-squared:  0.7446 
## F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10</code></pre>
<p>At this point it is good to stop and see what we have got. We have the formula call (we know this one), some stuff about the residuals, stuff about the coefficients (most important for us), and some diagnostics (including the notorious <span class="math inline">\(R^2\)</span>). We zoom in on the results about the coefficients. We have an estimation of the intercept (our <span class="math inline">\(\alpha\)</span> of above) and of <code>wt</code> (our <span class="math inline">\(\beta\)</span> of above). For both, we have as well a standard error, a <span class="math inline">\(t\)</span>-value, a probability and a bunch of stars. What do they all mean again? We focus on <code>wt</code> here (typically we are less interested in the constant or intercept).</p>
<p>The estimate is easy; that is <span class="math inline">\(\beta\)</span> or the marginal effect of <span class="math inline">\(x\)</span> on <span class="math inline">\(y\)</span>. So, increasing <span class="math inline">\(x\)</span> with 1 (or with a 1000 lbs) decreases the miles per gallon with 5.3445 (which is quite lot).</p>
<p>The standard error denote thes <em>precision</em> of the estimate. As a rule of thumb: you know with 95% centainty that the true value of <span class="math inline">\(\beta\)</span> lies within the interval [estimate - 2 <span class="math inline">\(\times\)</span> standard error, estimate + 2 <span class="math inline">\(\times\)</span> standard error]. The standard error is very important and is used to <strong>test</strong> possible values of the parameter. One of the most important tests is whether <span class="math inline">\(\beta=0\)</span>. Why? Because, if <span class="math inline">\(\beta=0\)</span> then the variable <code>wt</code> does nothing on <code>mpg</code>. This specific test is always denoted by the <span class="math inline">\(t\)</span>-value, its associated probability and the corresponding star thingies. In this case, the <span class="math inline">\(t\)</span>-value is high in an absolute sense, so it is <em>very</em> improbable that the estimate could be zero (somehting like a probability of 0.0000000001 which is small indeed), and the stars neatly indicate that this probability (of <span class="math inline">\(\beta=0\)</span> is smaller than 0.001.</p>
<p>One nice trick is to plot the regression line in the scatterplot above. One can do so by the command <code>abline()</code> or:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(mpg~wt, mtcars)
<span class="kw">abline</span>(<span class="kw">lm</span>(mpg~wt, mtcars))</code></pre></div>
<div class="figure">
<img src="unnamed-chunk-29-1.png" alt="A scatterplog between miles per gallon and car weight with regression line." width="672" />
<p class="caption">
(#fig:unnamed-chunk-29)A scatterplog between miles per gallon and car weight with regression line.
</p>
</div>
</div>
<div id="specificion-issues" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Specificion issues</h3>
<p>I can imagine that you are not very satisfied yet with the analysis. First of all, the relation between <code>mpg</code> and <code>wt</code> might be nonlinear and, secondly, you would like to include additional variables. First we look at the possible nonlinearity in the regression relation (note that we can use the regression formula as before, but that we can specify logarithmic relations by <code>log()</code>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">logmodel &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(mpg)~<span class="kw">log</span>(wt), mtcars)
<span class="kw">summary</span>(logmodel)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(mpg) ~ log(wt), data = mtcars)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.18141 -0.10681 -0.02125  0.08109  0.26930 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.90181    0.08790   44.39  &lt; 2e-16 ***
## log(wt)     -0.84182    0.07549  -11.15 3.41e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1334 on 30 degrees of freedom
## Multiple R-squared:  0.8056, Adjusted R-squared:  0.7992 
## F-statistic: 124.4 on 1 and 30 DF,  p-value: 3.406e-12</code></pre>
<p>We have now the same type of output as before, but I would like to focus on two things here. First, the <span class="math inline">\(R^2\)</span> has gone up and that is what you typically get in the social sciences. Logarithmically transformed variables usually <strong>fit</strong> better. Secondly, the interpretation of the estimate now differs. It has become an elasticity with size <span class="math inline">\(-0.84\)</span>, which is quite high again. If the car doubles in weights, the fuel efficiency of the car goes down by 84%!</p>
<p>Secondly, you might want to include other variables, such as being a foreing car (opposite to a car from USA) (<code>vs</code>), the number of cylinders (<code>cyl</code>), the gross horsepower (<code>hp</code>) and how quick the car does over a quarter of a mile (<code>qsec</code>). Again, we are not interested in these additional variables or whether they crank up the <span class="math inline">\(R^2\)</span>. The only thing we are interested is in whether the coefficient of <code>log(wt)</code> changes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">extendedmodel &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(mpg)~<span class="kw">log</span>(wt)+vs+cyl +<span class="st"> </span>hp +<span class="st"> </span>qsec, mtcars)
<span class="kw">summary</span>(extendedmodel)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(mpg) ~ log(wt) + vs + cyl + hp + qsec, data = mtcars)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.201746 -0.065242 -0.009506  0.079809  0.205166 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.5280554  0.4610947   7.651 4.04e-08 ***
## log(wt)     -0.6514583  0.1509786  -4.315 0.000205 ***
## vs          -0.0149215  0.0863277  -0.173 0.864111    
## cyl         -0.0160253  0.0314486  -0.510 0.614651    
## hp          -0.0007670  0.0006861  -1.118 0.273786    
## qsec         0.0212017  0.0267153   0.794 0.434603    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1121 on 26 degrees of freedom
## Multiple R-squared:  0.8811, Adjusted R-squared:  0.8582 
## F-statistic: 38.53 on 5 and 26 DF,  p-value: 3.227e-11</code></pre>
<p>Clearly, the coefficient of <code>log(wt)</code> changes with the inclusion of additional variables. So there was unobserved heterogeneity bias in our baseline model (and most likely there still is in our extended model), even though the addional variables are not siginficant.</p>
</div>
<div id="reporting" class="section level3">
<h3><span class="header-section-number">4.2.4</span> Reporting</h3>
<p>Hopefully you agree that the regression output of above looks <strong>horrible</strong> and that you do not need all these statistics and stuff. Therefore, you need to construct your own table for presentation format. The minimum what should be in these tables are the coefficient names, the estimates, the standard errors (and the start would be nice as well), the <span class="math inline">\(R^2\)</span> and the number of observations used.</p>
<p>Unfortunately, creating tables of your own is a pain in the … Luckily, within <code>R</code> (and by the way in programs as <code>Stata</code> as well) you can do this automatically! In <code>R</code> there are several packages one can use. I prefer the package Stargazer and after using this package we get the following outcome for our logarithmic specification:<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">stargazer</span>(logmodel, extendedmodel, <span class="dt">header=</span><span class="ot">FALSE</span>, <span class="dt">type =</span> <span class="st">&quot;html&quot;</span>, <span class="dt">omit.stat =</span> <span class="kw">c</span>(<span class="st">&quot;rsq&quot;</span>, <span class="st">&quot;f&quot;</span>))</code></pre></div>
<table style="text-align:center">
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td colspan="2">
<em>Dependent variable:</em>
</td>
</tr>
<tr>
<td>
</td>
<td colspan="2" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td colspan="2">
log(mpg)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(1)
</td>
<td>
(2)
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
log(wt)
</td>
<td>
-0.842<sup>***</sup>
</td>
<td>
-0.651<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.075)
</td>
<td>
(0.151)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
vs
</td>
<td>
</td>
<td>
-0.015
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.086)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
cyl
</td>
<td>
</td>
<td>
-0.016
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.031)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
hp
</td>
<td>
</td>
<td>
-0.001
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.001)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
qsec
</td>
<td>
</td>
<td>
0.021
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
(0.027)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align:left">
Constant
</td>
<td>
3.902<sup>***</sup>
</td>
<td>
3.528<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.088)
</td>
<td>
(0.461)
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
Observations
</td>
<td>
32
</td>
<td>
32
</td>
</tr>
<tr>
<td style="text-align:left">
Adjusted R<sup>2</sup>
</td>
<td>
0.799
</td>
<td>
0.858
</td>
</tr>
<tr>
<td style="text-align:left">
Residual Std. Error
</td>
<td>
0.133 (df = 30)
</td>
<td>
0.112 (df = 26)
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
<em>Note:</em>
</td>
<td colspan="2" style="text-align:right">
<sup><em></sup>p&lt;0.1; <sup><strong></sup>p&lt;0.05; <sup></strong></em></sup>p&lt;0.01
</td>
</tr>
</table>
<p>Note that we now display both specifications, the first the univariate case and the second the multivariate case. This is now typically done in social science research. You start with a baseline and then add variables to check whether the variable of interest remains robust.</p>
</div>
<div id="internal-validation" class="section level3">
<h3><span class="header-section-number">4.2.5</span> Internal validation</h3>
<p>So, after done all modeling exercitions you are not done! Now, it is time to validate your results internally. Can you be confident of your results? Or is the parameter that you have found still suspect of possible biases. Here again come the three least squares assumptions:</p>
<ol style="list-style-type: decimal">
<li><p>No large outliers: we have checked that with our descriptive statistics and our scatterplot and it seems that assumption is met.</p></li>
<li><p>Both miles per gallon and car weight should be <em>i.i.d.</em>. We can reasonably assume that the sampling has been correctly and that this is the case.</p></li>
<li><p>The following condition should hold: <span class="math inline">\(E[\epsilon|X=x] = 0\)</span>. This one is dubious. Probably there is no reverse causality (difficult to image that miles per gallon would influence car weight), but most likely there are other factors that impact car weight and miles per gallon which are omitted (where is the car build, what is the car brand, etcetera.). One possible strategy here is to add additional variables until the parameter of interest remains robust (does not change anymore).</p></li>
</ol>
<p>Note that the number of observations in this case is only 32, so whether our standard errors are automatically normally distributed is highly questionable, but for the sake of the exposition (and the fact that small sample statistics are very complex) we leave it just with this observation.</p>
<!--chapter:end:03-linearregression.Rmd-->
</div>
</div>
</div>
<div id="network-analysis-with-r" class="section level1">
<h1><span class="header-section-number">5</span> Network analysis with <code>R</code></h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;igraph&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;igraphdata&quot;</span>)</code></pre></div>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">5.1</span> Introduction</h2>
</div>
<div id="creating-networks" class="section level2">
<h2><span class="header-section-number">5.2</span> Creating networks</h2>
<p>With the package <code>igraph</code> it is rather straighforward to create structures networks</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">graph.ring</span>(<span class="dv">500</span>)</code></pre></div>
<pre><code>## IGRAPH U--- 500 500 -- Ring graph
## + attr: name (g/c), mutual (g/l), circular (g/l)
## + edges:
##  [1]  1-- 2  2-- 3  3-- 4  4-- 5  5-- 6  6-- 7  7-- 8  8-- 9  9--10 10--11
## [11] 11--12 12--13 13--14 14--15 15--16 16--17 17--18 18--19 19--20 20--21
## [21] 21--22 22--23 23--24 24--25 25--26 26--27 27--28 28--29 29--30 30--31
## [31] 31--32 32--33 33--34 34--35 35--36 36--37 37--38 38--39 39--40 40--41
## [41] 41--42 42--43 43--44 44--45 45--46 46--47 47--48 48--49 49--50 50--51
## [51] 51--52 52--53 53--54 54--55 55--56 56--57 57--58 58--59 59--60 60--61
## [61] 61--62 62--63 63--64 64--65 65--66 66--67 67--68 68--69 69--70 70--71
## [71] 71--72 72--73 73--74 74--75 75--76 76--77 77--78 78--79 79--80 80--81
## + ... omitted several edges</code></pre>
<p>erdos.renyi.game(500, 0.005)</p>
<p>rewire(g1,each_edge(prob = 0.5))</p>
<p>barabasi.game(500)</p>
</div>
<div id="reading-networks" class="section level2">
<h2><span class="header-section-number">5.3</span> Reading networks</h2>
</div>
<div id="network-characteristics" class="section level2">
<h2><span class="header-section-number">5.4</span> Network characteristics</h2>
<!--chapter:end:04-networkanalysis.Rmd-->
</div>
</div>
<div id="in-conclusion" class="section level1">
<h1><span class="header-section-number">6</span> In conclusion</h1>
<p>To be written</p>
<!--chapter:end:05-conclusion.Rmd-->
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Some of the tools I use are actually quite old, even so far as from the 1970s and they are still very good.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Including <code>Markdown</code>, <code>LaTeX</code>, <code>Python</code>, <code>Git</code> and <code>GitHub</code>.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p><a href="https://cran.r-project.org/web/packages/available_packages_by_name.html">CRAN packages</a> give a great overview of all the official packages out there and the wide range of applications, and again they are all free!<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>To get nice tables directly into <code>Word</code>, you need something else (as you can imagine, because <code>Word</code> is not scriptable). With Stargazer shoud give the command as such <code>stargazer(logmodel, extendedmodel, out = &quot;table1.txt&quot;,omit.stat = c(&quot;rsq&quot;, &quot;f&quot;))</code> and there after you can read in and edit the table <code>table1.txt</code>in <code>Word</code>.<a href="#fnref4">↩</a></p></li>
</ol>
</div>
<!--bookdown:body:end-->
            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->

<!--bookdown:config-->

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
